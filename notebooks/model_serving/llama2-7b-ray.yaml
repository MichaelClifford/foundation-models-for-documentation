apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  labels:
    controller-tools.k8s.io: '1.0'
  name: test-llama2
  namespace: default
spec:
  autoscalerOptions:
    idleTimeoutSeconds: 60
    imagePullPolicy: Always
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi
    upscalingMode: Default
  enableInTreeAutoscaling: false
  headGroupSpec:
    rayStartParams:
      block: 'true'
      dashboard-host: 0.0.0.0
      num-gpus: '0'
    serviceType: ClusterIP
    template:
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: test-llama2
                  operator: In
                  values:
                  - test-llama2
        containers:
        - env:
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: RAY_USE_TLS
            value: '0'
          - name: RAY_TLS_SERVER_CERT
            value: /home/ray/workspace/tls/server.crt
          - name: RAY_TLS_SERVER_KEY
            value: /home/ray/workspace/tls/server.key
          - name: RAY_TLS_CA_CERT
            value: /home/ray/workspace/tls/ca.crt
          image: quay.io/project-codeflare/ray:2.5.0-py38-cu116
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - ray stop
          name: ray-head
          ports:
          - containerPort: 6379
            name: gcs
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          - containerPort: 8000
            name: serve
          resources:
            limits:
              cpu: 2
              memory: 8G
              nvidia.com/gpu: 0
            requests:
              cpu: 2
              memory: 8G
              nvidia.com/gpu: 0
        imagePullSecrets: []
  rayVersion: 2.5.0
  workerGroupSpecs:
  - groupName: small-group-test-llama2
    maxReplicas: 1
    minReplicas: 1
    rayStartParams:
      block: 'true'
      num-gpus: '1'
    replicas: 1
    template:
      metadata:
        annotations:
          key: value
        labels:
          key: value
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: test-llama2
                  operator: In
                  values:
                  - test-llama2
        containers:
        - env:
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: RAY_USE_TLS
            value: '0'
          - name: RAY_TLS_SERVER_CERT
            value: /home/ray/workspace/tls/server.crt
          - name: RAY_TLS_SERVER_KEY
            value: /home/ray/workspace/tls/server.key
          - name: RAY_TLS_CA_CERT
            value: /home/ray/workspace/tls/ca.crt
          image: quay.io/project-codeflare/ray:2.5.0-py38-cu116
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - ray stop
          name: machine-learning
          resources:
            limits:
              cpu: 4
              memory: 24G
              nvidia.com/gpu: 1
            requests:
              cpu: 4
              memory: 24G
              nvidia.com/gpu: 1
        imagePullSecrets: []
        initContainers:
        - command:
          - sh
          - -c
          - until nslookup $RAY_IP.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local;
            do echo waiting for myservice; sleep 2; done
          image: busybox:1.28
          name: init-myservice
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    odh-ray-cluster-service: test-llama2-head-svc
  name: ray-dashboard-test-llama2
  namespace: default
spec:
  port:
    targetPort: dashboard
  to:
    kind: Service
    name: test-llama2-head-svc